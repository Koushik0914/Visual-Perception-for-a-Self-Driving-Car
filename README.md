# Visual-Perception-System-for-a-Self-Driving-Car
This dissertation focuses on the design and implementation of a visual perception system for self-driving cars, aimed at enhancing driving safety and efficiency. The primary objective was to develop a system capable of accurately detecting lane markings and vehicles on the road in real-time, thereby enabling autonomous vehicles to navigate effectively. To achieve this, a multi-faceted approach was adopted, encompassing techniques such as perspective transformation, color thresholding, sliding window detection, and polynomial function fitting for lane detection, alongside the integration of a pre-trained object detection network, MobileNet-SSD, for vehicle detection.
	The findings of this research showcase the successful implementation of a lightweight and efficient perception system capable of simultaneous lane and vehicle detection. Through experimentation , it was demonstrated that the system could accurately identify lane markings and vehicles. While limitations were identified, particularly in handling real-world complexities like partial obstructions and varying lighting conditions, the overall effectiveness and potential of the proposed perception system were underscored.
	The significance of these findings lies in their implications for the advancement of autonomous driving technology. By developing a robust visual perception system capable of real-time lane and vehicle detection, this research contributes to the ongoing efforts to enhance the safety and reliability of self-driving vehicles. Moreover, the methodology and insights gained from this study pave the way for future research endeavors aimed at addressing the identified limitations and further refining the perception system for broader applicability and improved performance.

Keywords: Visual Perception System; Lane Detection; Vehicle Detection; sliding window;
                   MobileNet-SSD.
